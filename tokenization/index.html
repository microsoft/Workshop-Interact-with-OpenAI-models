<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-concepts/Understand-Tokens" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.1">
<title data-rh="true">Tokenization | Learn how to interact with OpenAI models</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://microsoft.github.io/Workshop-Interact-with-OpenAI-models/tokenization/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Tokenization | Learn how to interact with OpenAI models"><meta data-rh="true" name="description" content="We&#x27;ve mentioned &quot;tokens&quot; a few times in previous lessons, but we didn&#x27;t explain what those were and why they matter. Let&#x27;s discuss that now."><meta data-rh="true" property="og:description" content="We&#x27;ve mentioned &quot;tokens&quot; a few times in previous lessons, but we didn&#x27;t explain what those were and why they matter. Let&#x27;s discuss that now."><link data-rh="true" rel="icon" href="/Workshop-Interact-with-OpenAI-models/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://microsoft.github.io/Workshop-Interact-with-OpenAI-models/tokenization/"><link data-rh="true" rel="alternate" href="https://microsoft.github.io/Workshop-Interact-with-OpenAI-models/tokenization/" hreflang="en"><link data-rh="true" rel="alternate" href="https://microsoft.github.io/Workshop-Interact-with-OpenAI-models/tokenization/" hreflang="x-default"><script>!function(e,t,n,c,a,r,s){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},(r=t.createElement(c)).async=1,r.src="https://www.clarity.ms/tag/gxhc6407pe",(s=t.getElementsByTagName(c)[0]).parentNode.insertBefore(r,s)}(window,document,"clarity","script")</script><link rel="stylesheet" href="/Workshop-Interact-with-OpenAI-models/assets/css/styles.fb442d0c.css">
<script src="/Workshop-Interact-with-OpenAI-models/assets/js/runtime~main.41b7949e.js" defer="defer"></script>
<script src="/Workshop-Interact-with-OpenAI-models/assets/js/main.a9906fba.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><a class="navbar__brand" href="/Workshop-Interact-with-OpenAI-models/"><div class="navbar__logo"><img src="/Workshop-Interact-with-OpenAI-models/img/logo-ws3.png" alt="Workshop: Learn how to interact with OpenAI models" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Workshop-Interact-with-OpenAI-models/img/logo-ws3.png" alt="Workshop: Learn how to interact with OpenAI models" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Learn how to interact with OpenAI models</b></a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Workshop-Interact-with-OpenAI-models/">Welcome</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Workshop-Interact-with-OpenAI-models/setup/">Get started</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item red"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/Workshop-Interact-with-OpenAI-models/ai-models/">Core Concepts</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Workshop-Interact-with-OpenAI-models/ai-models/">AI Models &amp; Deployments</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Workshop-Interact-with-OpenAI-models/llms/">Large Language Model (LLM)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Workshop-Interact-with-OpenAI-models/tokenization/">Tokenization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Workshop-Interact-with-OpenAI-models/generative-ai/"> Generative AI</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item red"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="true" href="/Workshop-Interact-with-OpenAI-models/labs/Basic-Prompting/"> Labs</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Workshop-Interact-with-OpenAI-models/labs/Basic-Prompting/">Basic Prompting</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Workshop-Interact-with-OpenAI-models/labs/Conversation-history/">Conversation history</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Workshop-Interact-with-OpenAI-models/labs/System-Message/">System Message</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Workshop-Interact-with-OpenAI-models/labs/Prompt-engineering-techniques/">Prompt engineering techniques</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Workshop-Interact-with-OpenAI-models/labs/Add-Knowledge/">Add knowledge</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Workshop-Interact-with-OpenAI-models/labs/Function-Calling/">Function Calling</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Workshop-Interact-with-OpenAI-models/labs/Create-Images/">Create Images</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item red"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="true" href="/Workshop-Interact-with-OpenAI-models/summary/">Wrap-Up</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Workshop-Interact-with-OpenAI-models/summary/">What We&#x27;ve Learned</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Workshop-Interact-with-OpenAI-models/next-steps/">Things to try text</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Workshop-Interact-with-OpenAI-models/at-home/">At home</a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Workshop-Interact-with-OpenAI-models/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Core Concepts</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Tokenization</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Tokenization</h1></header><p>We&#x27;ve mentioned &quot;tokens&quot; a few times in previous lessons, but we didn&#x27;t explain what those were and why they matter. Let&#x27;s discuss that now.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-tokenization">What is Tokenization?<a href="#what-is-tokenization" class="hash-link" aria-label="Direct link to What is Tokenization?" title="Direct link to What is Tokenization?">â€‹</a></h2>
<p>The OpenAI natural language models don&#x27;t operate on words or characters as units of text, but instead use something in-between: <strong>tokens.</strong> By <a href="https://platform.openai.com/docs/introduction/tokens" target="_blank" rel="noopener noreferrer">definition</a> tokens are text &quot;chunks&quot; that represent <em>commonly occuring sequences of characters</em> in the large language training dataset.</p>
<ul>
<li>A token can be a single character, fraction of a word, or an entire word.</li>
<li>Many common words are represented by a single token.</li>
<li>Less common words are represented by multiple tokens.</li>
</ul>
<p><strong>Tokenization</strong> is now the process by which text data (e.g., &quot;prompt&quot;) gets <em>deconstructed</em> into a sequence of tokens. The model can then generate the next token in sequence for text &#x27;completion&#x27;. We&#x27;ll see concrete examples of tokenization later in this lesson.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-are-tokens-used">How are Tokens Used?<a href="#how-are-tokens-used" class="hash-link" aria-label="Direct link to How are Tokens Used?" title="Direct link to How are Tokens Used?">â€‹</a></h2>
<p>Given an input prompt, the natural language models generate completions one token at a time. However, the generated token is not deterministic. At each step, the model outputs a list of all possible tokens with associated weights. The API samples one token from this list, with heavily-weighted tokens more likely to be selected than the others.</p>
<p><img loading="lazy" alt="Alt Text" src="/Workshop-Interact-with-OpenAI-models/assets/images/llm-002-392e502091b9423ce85a7a1db1c258d2.png" width="2052" height="352" class="img_ev3q"></p>
<p>It then adds that token to the prompt and repeats the process until the &quot;max token count&quot; limit (context window) is met for the completion - or until the model generates a special &quot;stop token&quot;, which halts further token generation. (This <a href="https://bea.stollnitz.com/blog/how-gpt-works/" target="_blank" rel="noopener noreferrer">blog post</a> by Beatriz Stollnitz explains the process in detail.)</p>
<p>This is how the model generates completions of one or more words, and why those completions can change from invocation to invocation.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-does-it-matter">Why Does It Matter?<a href="#why-does-it-matter" class="hash-link" aria-label="Direct link to Why Does It Matter?" title="Direct link to Why Does It Matter?">â€‹</a></h2>
<p>To understand why tokenization matters, we need to think about two aspects of deployed models: <em>token limits</em> and <em>token pricing</em>.</p>
<p><strong>Token Limits</strong>. Every model has a context window defined as the maximum number of tokens it can process for a single request. For instance, older gpt-3.5-turbo models have a 4K token limit (context) for each request. The token limit is <em>shared between prompt and completion</em>. Because the completion gets added to the prompt in order to generate the next token, it becomes necessary to fit both within the total context window for a single request.</p>
<p><strong>Token Pricing</strong>. Like with any API, model deployment usage incurs costs based on the model type and version. Currently, model pricing is tied to number of tokens used, with different price points possible for each model type or version.</p>
<p>The table below shows the context window (max tokens) and the model pricing (billed in 1K increments) for Azure OpenAI Models.</p>
<p><img loading="lazy" alt="Token Pricing" src="/Workshop-Interact-with-OpenAI-models/assets/images/aoia-pricing-tokens-ee857536d0519b526a2b31062575f591.png" width="1473" height="608" class="img_ev3q"></p>
<p>Note how newer models like gpt-4-32k have much larger token limits: up to 32,768 tokens. This not only allows for longer completions but also much larger prompts. This is particularly useful for prompt engineering, as we&#x27;ll see later.</p>
<p>Keep in mind that usage cost is correspondingly higher. Prompt engineering techniques can also help improve cost efficiency by crafting prompts that minimize token usage costs without sacrficing quality of responses.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="openai-tokenizer-tool">OpenAI Tokenizer Tool<a href="#openai-tokenizer-tool" class="hash-link" aria-label="Direct link to OpenAI Tokenizer Tool" title="Direct link to OpenAI Tokenizer Tool">â€‹</a></h2>
<p>Want to get a better sense of how tokenization works on real text? Use <a href="https://platform.openai.com/tokenizer" target="_blank" rel="noopener noreferrer"><strong>OpenAI Tokenizer</strong></a> - a free online tool that visualizes the tokenization and displays the total token count for the given text data.</p>
<p><a href="https://help.openai.com/articles/4936856-what-are-tokens-and-how-to-count-them" target="_blank" rel="noopener noreferrer">ðŸ”– Learn More:</a></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="try-the-example">Try The Example<a href="#try-the-example" class="hash-link" aria-label="Direct link to Try The Example" title="Direct link to Try The Example">â€‹</a></h3>
<p>Visit the site and click &quot;show example&quot; to see it in action as shown below. Each color-coded segment represents a single token, with the total token count displayed below (<strong>57 tokens</strong>).</p>
<p>Note how &quot;1234567890&quot; and &quot;underlying&quot; have the same string lengths - but the former counts for 4 tokens while the latter counts for 1. Also observe how punctuation (&quot;:&quot;,&quot;.&quot;) take up 1 token each, cutting into prompt token limits.</p>
<p><img loading="lazy" src="/Workshop-Interact-with-OpenAI-models/assets/images/tokenizer-example-30354110d0fda1fedd261a2223fd80c8.png" width="730" height="619" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="try-the-exercises">Try The Exercises<a href="#try-the-exercises" class="hash-link" aria-label="Direct link to Try The Exercises" title="Direct link to Try The Exercises">â€‹</a></h3>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>YOUR TURN</div><div class="admonitionContent_BuS1"><p>Visit <a href="https://platform.openai.com/tokenizer" target="_blank" rel="noopener noreferrer"><strong>https://platform.openai.com/tokenizer</strong></a>. Clear the tool before each exercise. Enter the exercise text into the Tokenizer and observe the output - it should update interactively.</p></div></div>
<p><strong>Exercise 1:</strong> As a common word, &quot;apple&quot; requires only one token.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">apple</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Exercise 2:</strong>  The word &quot;blueberries&quot; requires two tokens: &quot;blue&quot; and &quot;berries&quot;.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">blueberries</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Exercise 3:</strong> Proper names generally require multiple tokens (unless common)</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">SkarsgÃ¥rd</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>It&#x27;s this token representation that allows AI models to generate words that are not in any dictionary, but without having to generate text on a letter-by-letter basis (which could easily result in gibberish).</p>
<p><strong>Build your intuition by trying out other words or phrases.</strong></p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Workshop-Interact-with-OpenAI-models/llms/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Large Language Model (LLM)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Workshop-Interact-with-OpenAI-models/generative-ai/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label"> Generative AI</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#what-is-tokenization" class="table-of-contents__link toc-highlight">What is Tokenization?</a></li><li><a href="#how-are-tokens-used" class="table-of-contents__link toc-highlight">How are Tokens Used?</a></li><li><a href="#why-does-it-matter" class="table-of-contents__link toc-highlight">Why Does It Matter?</a></li><li><a href="#openai-tokenizer-tool" class="table-of-contents__link toc-highlight">OpenAI Tokenizer Tool</a><ul><li><a href="#try-the-example" class="table-of-contents__link toc-highlight">Try The Example</a></li><li><a href="#try-the-exercises" class="table-of-contents__link toc-highlight">Try The Exercises</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2024 Learn how to interact with OpenAI models. Microsoft AI Tour.</div></div></div></footer></div>
</body>
</html>